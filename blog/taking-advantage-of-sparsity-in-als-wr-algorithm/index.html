<!DOCTYPE html>
<html lang="en">
<head>

        <title>Taking Advantage of Sparsity in the ALS-WR Algorithm</title>
        <meta charset="utf-8" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">

        <link rel="stylesheet" type="text/css" href="/theme/gumby.css" />
        <link rel="stylesheet" type="text/css" href="/theme/style.css" />
        <link rel="stylesheet" type="text/css" href="/theme/pygment.css" />

        <script src="/theme/js/libs/modernizr-2.6.2.min.js"></script>


              <script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-71898636-1', 'auto');
                ga('send', 'pageview');

              </script>


</head>

<body id="index" class="home">


    <div class="container">

        <div class="row">

          <header id="banner" class="body">
              <h1><a href="/">Ben Lindsay <strong></strong></a></h1>
          </header><!-- /#banner -->

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>
              <ul class="columns">
                  <li >
                      <a href="/">Home</a>
                  </li>
            <li class="active"><a href="/blog/">Blog</a></li>
            <li ><a href="/projects/">Projects</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">


            <header>
              <h2 class="entry-title">
                <a href="/blog/taking-advantage-of-sparsity-in-als-wr-algorithm/" rel="bookmark"
                   title="Permalink to Taking Advantage of Sparsity in the ALS-WR Algorithm">Taking Advantage of Sparsity in the ALS-WR Algorithm</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2017-02-11T23:25:00-05:00">
                Sat 11 February 2017
              </abbr>
            </footer><!-- /.post-info -->
            <div class="spacer"></div>
            <div class="entry-content">
              <p>As a part of the <a class="reference external" href="http://penndsg.com">Penn Data Science Group</a> which I co-founded with <a class="reference external" href="http://jennhwang.me/">Jenn Hwang</a>, I'm starting on a team project aimed at developing a recommender system using Yelp data provided for the <a class="reference external" href="https://www.yelp.com/dataset_challenge">Yelp Dataset Challenge</a>. Since the Alternating-Least-Squares with Weighted-<span class="math">\(\lambda\)</span>-Regularization (ALS-WR) algorithm seems to be a popular algorithm for recommender systems, I'm testing it on our Yelp dataset. It was developed for the <a class="reference external" href="http://www.netflixprize.com/">Netflix Prize</a> competition, which also involved a sparse matrix of reviewers by items being reviewed.</p>
<p>While searching for resources on the ALS-WR algorithm, I came across <a class="reference external" href="http://online.cambridgecoding.com/notebooks/mhaller/predicting-user-preferences-in-python-using-alternating-least-squares">an excellent tutorial</a> that walks you through the theory and how to implement the algorithm using python on a small dataset of movie reviews. It even provides a <a class="reference external" href="https://s3-eu-west-1.amazonaws.com/com.cambridgecoding.students/mhaller/notebooks/654ddb1334a7f8246ca48d91dd98b653/notebook.ipynb">link to download a Jupyter Notebook</a> that you can run and see the algorithm in action. Having this notebook to toy around with was extremely helpful in familiarizing myself with the algorithm. However, as I compared the code in the notebook to the math in the blog post and in the <a class="reference external" href="http://www.grappa.univ-lille3.fr/~mary/cours/stats/centrale/reco/paper/MatrixFactorizationALS.pdf">original paper</a>, it seemed like it wasn't taking full advantage of the sparsity of the ratings matrix <span class="math">\(R\)</span>, which is a key feature of this type of problem. By slightly changing a couple lines in this code, I was able to dramatically reduce the computation time by taking advantage of the sparsity.</p>
<div class="section" id="the-model">
<h2>The Model</h2>
<p>I won't walk through all the details because the tutorial already does that really well, but I'll give enough background to explain the change I made and why it speeds up the computation.</p>
<p>We start with a matrix <span class="math">\(R\)</span> of size <span class="math">\((m \times n)\)</span> where each row represents one of the <span class="math">\(m\)</span> users and each column represents one of the <span class="math">\(n\)</span> movies. Most of the matrix contains 0's since most users only review a small subset of the available movies. The dataset used in the tutorial contains only about 6% nonzero values. We want to generate a low-rank approximation for <span class="math">\(R\)</span> such that <span class="math">\(R \approx P^TQ\)</span>, where <span class="math">\(P^T\)</span> is size <span class="math">\((m \times k)\)</span> and <span class="math">\(Q\)</span> is size <span class="math">\((k \times n)\)</span>, as shown below (image borrowed from the <a class="reference external" href="http://online.cambridgecoding.com/notebooks/mhaller/predicting-user-preferences-in-python-using-alternating-least-squares">tutorial</a>):</p>
<img alt="ALS-WR Matrix Schematic" src="/images/als-wr-matrix-schematic.png" />
<p>The columns of the resulting matrices <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> turn out to contain columns with <span class="math">\(k\)</span> latent features about the users and movies, respectively. The <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> matrices are calculated iteratively, by fixing one and solving for the other, then repeating while alternating which one is fixed. As a side note, in case you want to look at the paper, the notation is a little different. They use <span class="math">\(U\)</span> and <span class="math">\(M\)</span> instead of <span class="math">\(P\)</span> and <span class="math">\(Q\)</span>, and <span class="math">\(n_u\)</span> and <span class="math">\(n_m\)</span> instead of <span class="math">\(m\)</span> and <span class="math">\(n\)</span>. I'll stick with the tutorial notation in this post.</p>
<p>The equations for solving for <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> are quite similar, so let's just look at the equation for <span class="math">\(P\)</span>. In each iteration, the column for each user in <span class="math">\(P\)</span> is generated with the following equation:</p>
<p><span class="math">\(\mathbf{p}_i = A_i^{-1} V_i\)</span> where <span class="math">\(A_i = Q_{I_i} Q_{I_i}^T + \lambda n_{p_i} E\)</span> and <span class="math">\(V_i = Q_{I_i} R^T(i, I_i)\)</span></p>
<p>Here, <span class="math">\(E\)</span> is the <span class="math">\((k \times k)\)</span> identity matrix, <span class="math">\(n_{p_i}\)</span> is the number of movies rated by user <span class="math">\(i\)</span>, and <span class="math">\(I_i\)</span> is the set of all movies rated by user <span class="math">\(i\)</span>. That <span class="math">\(I_i\)</span> in <span class="math">\(Q_{I_i}\)</span> and <span class="math">\(R(i, I_i)\)</span> means we are selecting only the columns for movies rated by user <span class="math">\(i\)</span>, and the way that selection is made makes all the difference.</p>
</div>
<div class="section" id="selecting-columns">
<h2>Selecting Columns</h2>
<p>In the tutorial, the key lines to generate each <span class="math">\(\mathbf{p}_i\)</span> look like this:</p>
<pre class="code python literal-block">
<span class="n">Ai</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">Ii</span><span class="p">),</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">+</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">nui</span> <span class="o">*</span> <span class="n">E</span>
<span class="n">Vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">Ii</span><span class="p">),</span> <span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
<span class="n">P</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Ai</span><span class="p">,</span><span class="n">Vi</span><span class="p">)</span>
</pre>
<p>Notice that in the equation for <span class="math">\(A_i\)</span>, the way it removes columns for movies that weren't reviewed by user <span class="math">\(i\)</span> is creating a <span class="math">\((n \times n)\)</span> matrix with the elements of <span class="math">\(I_i\)</span> along the diagonal, then doing a <span class="math">\((n \times n) \times (n \times k)\)</span> matrix multiplication between that and <span class="math">\(Q^T\)</span>, which zeroes out columns of <span class="math">\(Q\)</span> for movies user <span class="math">\(i\)</span> did not review. This matrix multiplication is an expensive operation that (naively) has a complexity of <span class="math">\(O(kn^2)\)</span> (although probably a bit better with the <em>numpy</em> implementation). A similar operation is done in the <span class="math">\(V_i\)</span> calculation. Even though this is not as expensive (complexity of <span class="math">\(O(n^2)\)</span>), that's still an operation we'd like to avoid if possible.</p>
<p>On reading the equations and Matlab algorithm implementation in the original paper, I noticed that rather than zeroing out unwanted columns, they actually remove those columns by creating a submatrix of <span class="math">\(Q\)</span> and a subvector of <span class="math">\(\mathbf{r}_i\)</span>. This does 2 important things: First, it lets us remove that inner matrix multiplications. Second, it dramatically reduces the cost of the remaining matrix multiplications. Since we have a density of only about 6% in our <span class="math">\(R\)</span> matrix, the cost of both <span class="math">\(Q_{I_i}Q_{I_i}^T\)</span> and <span class="math">\(Q_{I_i}R^T(i,I_i)\)</span> should theoretically be reduced to about 6% of their original costs, since the complexities of those operations (<span class="math">\(O(nk^2)\)</span> and <span class="math">\(O(nk)\)</span>) are both linearly dependent on <span class="math">\(n\)</span>. Here's the code that replaces the 3 lines shown above:</p>
<pre class="code python literal-block">
<span class="c1"># Get array of nonzero indices in row Ii</span>
<span class="n">Ii_nonzero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">Ii</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Select subset of Q associated with movies reviewed by user i</span>
<span class="n">Q_Ii</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[:,</span> <span class="n">Ii_nonzero</span><span class="p">]</span>
<span class="c1"># Select subset of row R_i associated with movies reviewed by user i</span>
<span class="n">R_Ii</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">Ii_nonzero</span><span class="p">]</span>
<span class="n">Ai</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q_Ii</span><span class="p">,</span> <span class="n">Q_Ii</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">nui</span> <span class="o">*</span> <span class="n">E</span>
<span class="n">Vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q_Ii</span><span class="p">,</span> <span class="n">R_Ii</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">P</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Ai</span><span class="p">,</span> <span class="n">Vi</span><span class="p">)</span>
</pre>
<p>By making that replacement and a similar one for the equations for <span class="math">\(\mathbf{q}_j\)</span>, a series of 15 iterations went from taking 15-16 minutes down to about 13 seconds—a ~70-fold speedup! Check out <a class="reference external" href="https://github.com/benlindsay/als-wr-tutorial/blob/master/modified_notebook.ipynb">the notebook with my updates</a> on GitHub, or clone the whole <a class="reference external" href="https://github.com/benlindsay/als-wr-tutorial">repo</a> to run it yourself.</p>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>The moral of the story here is that sometimes things that don't seem like a big deal at first glance can make huge changes in the performance of your algorithms. This exercise reinforced in my mind the value of spending a little extra time to make sure you understand the algorithm or tool you're using. And more specifically, if you have a sparse dataset, make that sparsity work for you.</p>
</div>
<script type='text/javascript'>if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div><!-- /.entry-content -->
            <div class="comments">
              <h3>Comments</h3>
              <div id="disqus_thread"></div>
              <script type="text/javascript">
                var disqus_identifier = "blog/taking-advantage-of-sparsity-in-als-wr-algorithm/";
                (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'https://benlindsay.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
              </script>
            </div>


        </div><!-- /.eleven.columns -->

<div class="three columns">

<!-- <h4>Pages</h4> -->

 <!-- <ul> -->
 <!--   -->
 <!--      <li><a href="/blog/">Blog</a></li> -->
 <!--   -->
 <!--      <li><a href="/projects/">Projects</a></li> -->
 <!--   -->
 <!--   -->
 <!--     -->
 <!--   -->
 <!--  </ul> -->

<!-- <h4>Categories</h4> -->
<!--  -->
<!-- <ul class="blank"> -->
<!-- 	 -->
<!-- 		<li><a href="/blog/">Blog</a></li> -->
<!-- 	 -->
<!-- 		<li><a href="/projects/">Projects</a></li> -->
<!-- 	 -->
<!-- </ul> -->
<!--  -->

<div class="smallspacer"></div>
<section id="sidebar-icons">
  <span class="fa-stack fa-lg">
    <a href="mailto:benjlindsay@gmail.com">
      <i class="fa fa-envelope-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="https://www.linkedin.com/in/benjlindsay">
      <i class="fa fa-linkedin-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="https://github.com/benlindsay">
      <i class="fa fa-github-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="http://penndsg.com/">
      <!-- <img style="display: inline-block; margin-top: 2px; margin-left: 4px" -->
      <!--      src="/images/pdsg_black_and_white.svg" -->
      <!--      alt="Penn Data Science Group" height=40px width=40px> -->
      <svg xmlns="http://www.w3.org/2000/svg" width="40px" height="40px"
           viewBox="0 0 800 800" preserveAspectRatio="xMidYMid meet"
           id="pdsg-logo" style="margin-top: 2px; margin-left: 4px">
        <style>
          .a{fill:#444;}
          .b{fill:#fff;}
        </style>
        <metadata class="undefined"></metadata>
        <rect width="800" height="800" rx="160" ry="160" class="a"/>
        <g transform="matrix(0.1 0 0 -0.1 49.95 762.85737)" class="b">
          <path d="m600 5213c0-1603 2-1651 45-1906 123-712 482-1366 1067-1943 268-265 496-449 806-651 370-240 791-436 967-450 64-5 82-2 195 36 278 93 664 308 1016 565 368 270 749 644 995 976 328 444 549 926 644 1408 61 306 58 215 62 1925l4 1567-2901 0-2900 0zm5717-925c-4-688-8-752-62-1020-56-282-173-612-304-858l-40-75-1 538 0 537-415 0-415 0 0-1064 0-1063-83-72-82-71-3 510-2 510-415 0-415 0 0-798 0-798-75-37c-42-20-80-37-85-37-7 0-10 594-10 1705l0 1705-410 0-410 0 0-1705c0-938-2-1705-5-1705-3 0-41 18-85 40l-80 40 0 2070 0 2070-415 0-415 0-2-1790-3-1790-82 71-83 70 0 765 0 764-415 0-415 0-2-247-3-248-52 100c-115 223-216 501-271 746-70 307-82 483-82 1222l0 557 2821 0 2821 0z" class="b"/>
          <path d="m2525 5630c-38-15-48-38-50-115l-3-75 40 0c69 0 178 99 153 140-7 11-99 60-112 59-4 0-17-4-28-9z" class="b"/>
        </g>
      </svg>
    </a>
  </span>
  <!-- <span class="fa-stack fa-lg"> -->
  <!--   <a href="https://bitbucket.org/benlindsay"> -->
  <!--     <i class="fa fa-bitbucket-square fa-stack-2x"></i> -->
  <!--   </a> -->
  <!-- </span> -->
</section>

<h4>Tags</h4>
  <ul class="blank">
    <li class="tag-1">
      <a href="/tag/python/">python</a>
(3)    </li>
    <li class="tag-50">
      <a href="/tag/recommender-systems/">recommender systems</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/als-wr/">als-wr</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/productivity/">productivity</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/data-visualization/">data visualization</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/machine-learning/">machine learning</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/numpy/">numpy</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/d3/">d3</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/bash/">bash</a>
(1)    </li>
</ul>


</div> </div><!-- /.row -->


</section>

       </div><!-- /.row -->
    </div><!-- /.container -->


       <div class="container.nopad bg">

    
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                    which takes great advantage of <a href="http://python.org">Python</a>.
                    <br />
                    Based on the <a target="_blank" href="http://gumbyframework.com">Gumby Framework</a>
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">





              </ul>
            </div>
          </div>
        </footer>

    </div>


<script type="text/javascript">
    var disqus_shortname = 'benlindsay';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
  <script src="/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="/theme/js/libs/gumby.min.js"></script>
  <script src="/theme/js/plugins.js"></script>
</body>
</html>