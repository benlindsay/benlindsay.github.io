<!DOCTYPE html>
<html lang="en">
<head>

        <title>Analyzing Larger-than-Memory Data on your Laptop</title>
        <meta charset="utf-8" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">

        <link rel="stylesheet" type="text/css" href="/theme/gumby.css" />
        <link rel="stylesheet" type="text/css" href="/theme/style.css" />
        <link rel="stylesheet" type="text/css" href="/theme/pygment.css" />

        <script src="/theme/js/libs/modernizr-2.6.2.min.js"></script>


              <script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-71898636-1', 'auto');
                ga('send', 'pageview');

              </script>


</head>

<body id="index" class="home">


    <div class="container">

        <div class="row">

          <header id="banner" class="body">
              <h1><a href="/">Ben Lindsay <strong></strong></a></h1>
          </header><!-- /#banner -->

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>
              <ul class="columns">
                  <li >
                      <a href="/">Home</a>
                  </li>
            <li class="active"><a href="/blog/">Blog</a></li>
            <li ><a href="/projects/">Projects</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">


            <header>
              <h2 class="entry-title">
                <a href="/blog/analyzing-larger-than-memory-data-on-your-laptop/" rel="bookmark"
                   title="Permalink to Analyzing Larger-than-Memory Data on your Laptop">Analyzing Larger-than-Memory Data on your Laptop</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2017-03-10T19:10:00-05:00">
                Fri 10 March 2017
              </abbr>
            </footer><!-- /.post-info -->
            <div class="spacer"></div>
            <div class="entry-content">
              <p>If you want to run some analysis on a dataset that's just a little too big to load into memory on your laptop, but you don't want to leave the comfort of using <a class="reference external" href="http://pandas.pydata.org/">Pandas</a> dataframes in a <a class="reference external" href="http://jupyter.org/">Jupyter</a> notebook, then <a class="reference external" href="http://dask.pydata.org/">Dask</a> may be just your thing. Dask is an amazing Python library that lets you do all your Pandas-style dataframe manipulations with just a few simple tweaks so you don't have to worry about Jupyter freezing up.</p>
<p>I'll demonstrate the benefits of Dask and some of its syntax by running a calculation on business reviews provided for the <a class="reference external" href="https://www.yelp.com/dataset_challenge">Yelp Dataset Challenge</a>, which contains 3.6 million business reviews. The reviews were provided in a file where each line is a JSON object with keys that include <code>&quot;business_id&quot;</code>,  <code>&quot;user_id&quot;</code>, <code>&quot;review_id&quot;</code>, <code>&quot;stars&quot;</code>, and others. I extracted about 90% of all the JSON objects associated with businesses in Champaign, Illinois to one file as a small dataset that can be loaded into Pandas, and about 90% of all the JSON objects associated with any US/Canada business into another file as a larger dataset that does not fit into a Pandas dataframe on my laptop. You can view the notebook with all the code below <a class="reference external" href="https://github.com/benlindsay/yelp-dataset-challenge/blob/master/ben-notebooks/pandas_dask_comparison.ipynb">here on GitHub</a>.</p>
<div class="section" id="baseline-prediction-method">
<h2>Baseline Prediction Method</h2>
<p>The baseline prediction method I'll show below is one of 4 methods discussed in <a class="reference external" href="http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf">this excellent survey of collaborative filtering recommender systems</a> by Michael Ekstrand, John Riedl, and Joseph Konstan. The methods are:</p>
<ol class="arabic simple">
<li>Predict by user's average rating</li>
<li>Predict by item's average rating (&quot;items&quot; are businesses in this case)</li>
<li>Predict by user's and item's average ratings</li>
<li>Predict by user's and item's average ratings with damping factors</li>
</ol>
<p>The 4th method ended up giving the best predictions on both the Champaign data and US/Canada training set. The damping factors reduce the weight placed on users or items with few reviews, making the prediction more robust. The necessary equations are 2.1, 2.4, and 2.5 in the survey linked above.</p>
<p>Equation 2.1 (<span class="math">\(b_{u,i} = \mu + b_u + b_i\)</span>) essentially says that if we want the baseline prediction for user <span class="math">\(u\)</span>'s rating of item <span class="math">\(i\)</span>, we can sum up the total average <span class="math">\(\mu\)</span>, the offset from the <span class="math">\(\mu\)</span>  corresponding to user <span class="math">\(u\)</span> (<span class="math">\(b_u\)</span>), and the offset from <span class="math">\(\mu + b_u\)</span> corresponding to item <span class="math">\(i\)</span> (<span class="math">\(b_i\)</span>).</p>
<p>The equations for <span class="math">\(b_u\)</span> and <span class="math">\(b_i\)</span> are</p>
<div class="math">
\begin{equation*}
b_u = \frac{1}{|I_u| + \beta_u}\sum_{i \in I_u} (r_{u,i} - \mu)
\end{equation*}
</div>
<div class="math">
\begin{equation*}
b_i = \frac{1}{|U_i| + \beta_i}\sum_{u \in U_i} (r_{u,i} - b_u - \mu)
\end{equation*}
</div>
<p>where <span class="math">\(r_{u_i}\)</span> is the actual rating of item (business) <span class="math">\(i\)</span> given by user <span class="math">\(u\)</span>, <span class="math">\(I_u\)</span> is the set of items rated by user <span class="math">\(u\)</span>, and <span class="math">\(U_i\)</span> is the set of users who rated business <span class="math">\(i\)</span>.</p>
</div>
<div class="section" id="loading-data">
<h2>Loading Data</h2>
<p>For all the following code blocks, assume we have the following imports:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">dask.bag</span> <span class="kn">as</span> <span class="nn">db</span>
</pre></div>
<p>First, let's compare the data loading process for the small and large datasets. In both cases, the data are in the form of a single file with one line of JSON data for each review. Loading the Champaign data using Pandas looks like this:</p>
<div class="highlight"><pre><span></span><span class="n">df_rev</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="s1">&#39;../preprocessed-data/all-champaign-reviews.json&#39;</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_rev_champaign</span> <span class="o">=</span> <span class="n">df_rev_champaign</span><span class="p">[[</span><span class="s1">&#39;review_id&#39;</span><span class="p">,</span> <span class="s1">&#39;business_id&#39;</span><span class="p">,</span> <span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;stars&#39;</span><span class="p">]]</span>
</pre></div>
<p>For the larger US/Canada training set, loading the data using Dask looks like this:</p>
<div class="highlight"><pre><span></span><span class="n">dict_bag</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">read_text</span><span class="p">(</span><span class="s1">&#39;../preprocessed-data/reviews_train.json&#39;</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">5e6</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">)</span>
<span class="n">df_rev</span> <span class="o">=</span> <span class="n">dict_bag</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;review_id&#39;</span><span class="p">,</span> <span class="s1">&#39;business_id&#39;</span><span class="p">,</span> <span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;stars&#39;</span><span class="p">])</span>
<span class="n">df_rev</span> <span class="o">=</span> <span class="n">df_rev</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
<p>When loading in larger-than-memory data, Dask splits the data into partitions no larger than <code>blocksize</code>. You want to ensure you have enough partitions to ensure your computer doesn't freeze, but too many will slow down the computation. For that reason, after I make a dataframe from a small subset of the features I read in, I repartition the data to reduce the number of partitions to 10. After the data are loaded in, you can treat your Dask datafame just like a Pandas dataframe (for the most part).</p>
</div>
<div class="section" id="computing-prediction-error">
<h2>Computing Prediction Error</h2>
<p>For these baseline tests, I use the root mean squared error (RMSE) to measure the baseline accuracy. When dealing with Pandas dataframes, I can use a function like this:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rmse_pandas</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">diff_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_sq</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
<p>In Dask, I can do the same thing with just an extra <code>.compute()</code> added, like so:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rmse_dask</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">diff_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_sq</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">())</span>
</pre></div>
<p>This is necessary because Dask uses &quot;lazy evaluation&quot; by default, and only computes results when you tell it to.</p>
</div>
<div class="section" id="splitting-dataframe-into-train-and-test-sets">
<h2>Splitting Dataframe into Train and Test Sets</h2>
<p>Splitting the Pandas dataframe:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">df_train_champaign</span><span class="p">,</span> <span class="n">df_test_champaign</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_rev_champaign</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
<p>Splitting the Dask dataframe:</p>
<div class="highlight"><pre><span></span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">df_rev</span><span class="o">.</span><span class="n">random_split</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<p>Unfortunately we can't use Scikit-learn on Dask dataframes, but a lot of the essential capabilities of Scikit-learn are implemented in Dask, or Dask compatible libraries.</p>
</div>
<div class="section" id="computing-baselines">
<h2>Computing Baselines</h2>
<p>Now here's the exciting part: the actual baseline computation uses the exact same code no matter whether it's a Dask or Pandas dataframe. Here's the function that computes the baseline predictions:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_baseline_rmse</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">beta_u</span><span class="p">,</span> <span class="n">beta_i</span><span class="p">,</span> <span class="n">rmse_func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    df_train and df_test are either Pandas or Dask dataframes</span>
<span class="sd">    that must contain the columns &#39;user_id&#39;, &#39;business_id&#39;, and &#39;stars&#39;.</span>
<span class="sd">    beta_u and beta_i are user and business damping factors, respectively.</span>
<span class="sd">    rmse_func is a function that computes the RMSE of the prediction</span>
<span class="sd">    and takes Pandas or Dask Series objects, depending on whether</span>
<span class="sd">    df_train and df_test are Pandas or Dask Dataframes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get mean rating of all training ratings</span>
    <span class="n">train_mean</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;stars&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="c1"># Get dataframe of b_u part of baseline for each user id</span>
    <span class="n">user_group</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;stars&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;user_id&#39;</span><span class="p">)</span>
    <span class="n">df_train_user</span> <span class="o">=</span> <span class="n">user_group</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">])[</span><span class="s1">&#39;stars&#39;</span><span class="p">]</span>
    <span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">train_mean</span> <span class="o">*</span> <span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;count&#39;</span><span class="p">])</span>
    <span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]</span> <span class="o">/=</span> <span class="p">(</span><span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;count&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_u</span><span class="p">)</span>
    <span class="c1"># Create column of b_u values corresponding to the user who made the review</span>
    <span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_train_user</span><span class="p">[[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;user_id&#39;</span><span class="p">)</span>
    <span class="c1"># Add column representing the expression inside the summation part of the b_i equation</span>
    <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;b_i_sum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;stars&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">train_mean</span>
    <span class="c1"># Average over each business to get the actual b_i values for each business</span>
    <span class="n">bus_group</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;business_id&#39;</span><span class="p">,</span> <span class="s1">&#39;b_i_sum&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;business_id&#39;</span><span class="p">)</span>
    <span class="n">df_train_bus</span> <span class="o">=</span> <span class="n">bus_group</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">])[</span><span class="s1">&#39;b_i_sum&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sum&#39;</span><span class="p">:</span> <span class="s1">&#39;b_i&#39;</span><span class="p">})</span>
    <span class="n">df_train_bus</span><span class="p">[</span><span class="s1">&#39;b_i&#39;</span><span class="p">]</span> <span class="o">/=</span> <span class="n">df_train_bus</span><span class="p">[</span><span class="s1">&#39;count&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_i</span>
    <span class="c1"># Join b_u and b_i columns to test dataframe</span>
    <span class="n">df_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_train_user</span><span class="p">[[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;user_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df_train_user</span><span class="p">[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">df_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_train_bus</span><span class="p">[[</span><span class="s1">&#39;b_i&#39;</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;business_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df_train_bus</span><span class="p">[</span><span class="s1">&#39;b_i&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="c1"># Predict and Compute error</span>
    <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;b_u&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;b_i&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_mean</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">rmse_func</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;stars&#39;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Error = {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
</pre></div>
<p>I call that function using either</p>
<div class="highlight"><pre><span></span><span class="n">compute_baseline_rmse</span><span class="p">(</span><span class="n">df_train_champaign</span><span class="p">,</span> <span class="n">df_test_champaign</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">rmse_pandas</span><span class="p">)</span>
</pre></div>
<p>for the Champaign Pandas dataframes or</p>
<div class="highlight"><pre><span></span><span class="n">compute_baseline_rmse</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">rmse_dask</span><span class="p">)</span>
</pre></div>
<p>for the US/Canada Dask dataframes. Note that even relatively simple calculations like these can still take a long time if you're just running on your laptop, especially if you more partitions than necessary.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>If you want to do dataframe manipulations or standard machine learning on a dataset that's just a little bigger than the memory you have available, I highly recommend Dask. For more complex computations or bigger datasets, you might want to stick with something fancier like Spark clusters in the cloud.</p>
</div>
<div class="section" id="acknowledgments">
<h2>Acknowledgments</h2>
<p>Thanks to <a class="reference external" href="http://arielrodriguezromero.com/">Ariel Rodriquez</a> for introducing me to Dask, and thanks to <a class="reference external" href="https://sakura9096.github.io/">Claire Zhang</a> for finding the survey of collaborative filtering systems.</p>
</div>
<script type='text/javascript'>if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div><!-- /.entry-content -->
            <div class="comments">
              <h3>Comments</h3>
              <div id="disqus_thread"></div>
              <script type="text/javascript">
                var disqus_identifier = "blog/analyzing-larger-than-memory-data-on-your-laptop/";
                (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'https://benlindsay.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
              </script>
            </div>


        </div><!-- /.eleven.columns -->

<div class="three columns">

<!-- <h4>Pages</h4> -->

 <!-- <ul> -->
 <!--   -->
 <!--      <li><a href="/blog/">Blog</a></li> -->
 <!--   -->
 <!--      <li><a href="/projects/">Projects</a></li> -->
 <!--   -->
 <!--   -->
 <!--     -->
 <!--   -->
 <!--  </ul> -->

<!-- <h4>Categories</h4> -->
<!--  -->
<!-- <ul class="blank"> -->
<!-- 	 -->
<!-- 		<li><a href="/blog/">Blog</a></li> -->
<!-- 	 -->
<!-- 		<li><a href="/projects/">Projects</a></li> -->
<!-- 	 -->
<!-- </ul> -->
<!--  -->

<div class="smallspacer"></div>
<section id="sidebar-icons">
  <span class="fa-stack fa-lg">
    <a href="mailto:benjlindsay@gmail.com">
      <i class="fa fa-envelope-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="https://www.linkedin.com/in/benjlindsay">
      <i class="fa fa-linkedin-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="https://github.com/benlindsay">
      <i class="fa fa-github-square fa-stack-2x"></i>
    </a>
  </span>
  <span class="fa-stack fa-lg">
    <a href="http://penndsg.com/">
      <!-- <img style="display: inline-block; margin-top: 2px; margin-left: 4px" -->
      <!--      src="/images/pdsg_black_and_white.svg" -->
      <!--      alt="Penn Data Science Group" height=40px width=40px> -->
      <svg xmlns="http://www.w3.org/2000/svg" width="40px" height="40px"
           viewBox="0 0 800 800" preserveAspectRatio="xMidYMid meet"
           id="pdsg-logo" style="margin-top: 2px; margin-left: 4px">
        <style>
          .a{fill:#444;}
          .b{fill:#fff;}
        </style>
        <metadata class="undefined"></metadata>
        <rect width="800" height="800" rx="160" ry="160" class="a"/>
        <g transform="matrix(0.1 0 0 -0.1 49.95 762.85737)" class="b">
          <path d="m600 5213c0-1603 2-1651 45-1906 123-712 482-1366 1067-1943 268-265 496-449 806-651 370-240 791-436 967-450 64-5 82-2 195 36 278 93 664 308 1016 565 368 270 749 644 995 976 328 444 549 926 644 1408 61 306 58 215 62 1925l4 1567-2901 0-2900 0zm5717-925c-4-688-8-752-62-1020-56-282-173-612-304-858l-40-75-1 538 0 537-415 0-415 0 0-1064 0-1063-83-72-82-71-3 510-2 510-415 0-415 0 0-798 0-798-75-37c-42-20-80-37-85-37-7 0-10 594-10 1705l0 1705-410 0-410 0 0-1705c0-938-2-1705-5-1705-3 0-41 18-85 40l-80 40 0 2070 0 2070-415 0-415 0-2-1790-3-1790-82 71-83 70 0 765 0 764-415 0-415 0-2-247-3-248-52 100c-115 223-216 501-271 746-70 307-82 483-82 1222l0 557 2821 0 2821 0z" class="b"/>
          <path d="m2525 5630c-38-15-48-38-50-115l-3-75 40 0c69 0 178 99 153 140-7 11-99 60-112 59-4 0-17-4-28-9z" class="b"/>
        </g>
      </svg>
    </a>
  </span>
  <!-- <span class="fa-stack fa-lg"> -->
  <!--   <a href="https://bitbucket.org/benlindsay"> -->
  <!--     <i class="fa fa-bitbucket-square fa-stack-2x"></i> -->
  <!--   </a> -->
  <!-- </span> -->
</section>

<h4>Tags</h4>
  <ul class="blank">
    <li class="tag-1">
      <a href="/tag/python/">python</a>
(4)    </li>
    <li class="tag-25">
      <a href="/tag/recommender-systems/">recommender systems</a>
(2)    </li>
    <li class="tag-50">
      <a href="/tag/als-wr/">als-wr</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/productivity/">productivity</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/big-data/">big data</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/d3/">d3</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/data-visualization/">data visualization</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/dask/">dask</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/machine-learning/">machine learning</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/numpy/">numpy</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/pandas/">pandas</a>
(1)    </li>
    <li class="tag-50">
      <a href="/tag/bash/">bash</a>
(1)    </li>
</ul>


</div> </div><!-- /.row -->


</section>

       </div><!-- /.row -->
    </div><!-- /.container -->


       <div class="container.nopad bg">

    
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                    which takes great advantage of <a href="http://python.org">Python</a>.
                    <br />
                    Based on the <a target="_blank" href="http://gumbyframework.com">Gumby Framework</a>
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">





              </ul>
            </div>
          </div>
        </footer>

    </div>


<script type="text/javascript">
    var disqus_shortname = 'benlindsay';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
  <script src="/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="/theme/js/libs/gumby.min.js"></script>
  <script src="/theme/js/plugins.js"></script>
</body>
</html>